---
title: "Business Intelligence Project"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |                             |
|--------------------------------------------|----------------------------|
| **Student ID Number**                        | 119630,135844,131038,104135 |
| **Student Name**                             | beasts                      |
| **BBIT 4.2 Group**                           | A&B&C                       |
| **BI Project Group Name/ID (if applicable)** | beasts                      |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```

# Load dataset

```{r}
insurance <- read.csv("data/insurance_info.csv")

```

# Exploratory Data Analysis

## Dimensions

```{r}
dim(insurance)
```

## Data Types

```{r}
sapply(insurance, class)
```

## Descriptive Statistics

### Measures of Frequency

```{r}
insurance_rating_freq <- insurance$rating
cbind(frequency = table(insurance_rating_freq),
      percentage = prop.table(table(insurance_rating_freq)) * 100)
```

### Measures of Central Tendency

```{r}
insurance_rating_mode <- names(table(insurance$rating))[
  which(table(insurance$rating) == max(table(insurance$rating)))
]
print(insurance_rating_mode)
```

## Measures of Distribution/Dispersion/Spread/Scatter/Variability

### Measure the distribution of the data for each variable

```{r}
summary(insurance)
```

### Measure the standard deviation of each variable

```{r}
library(e1071)

sapply(insurance[, c(6,8)], sd)
```

### Measure the variance of each variable

```{r}
sapply(insurance[, c(6,8)], var)
```

### Measure the kurtosis of each variable

```{r}
library(e1071)

sapply(insurance[, c(6, 8)], kurtosis, type = 2)

```

### Measure the skewness of each variable

```{r}
sapply(insurance[, c(6, 8)],  skewness, type = 2)
```

## Measures of Relationship

### Measure the covariance between variables

```{r}
insurance_cov <- cov(insurance[, c(6, 8)])
View(insurance_cov)

```

### Measure the correlation between variables

```{r}
insurance_cor <- cor(insurance[, c(6, 8)])
View(insurance_cor)
```

## Inferential Statistics

### Perform ANOVA

#### One-Way ANOVA

```{r}
insurance_one_way_anova <- aov(age ~ rating, data = insurance)
summary(insurance_one_way_anova)
```

#### Two-Way ANOVA

```{r}
insurance_two_way_anova <- aov(packagePrice ~ rating + age, # nolint
                                           data = insurance)
summary(insurance_two_way_anova)
```

## Qualitative Data Analysis

### Univariate plots

#### Create histograms

```{r}
insurance_age <- as.numeric(unlist(insurance[, 6]))
hist(insurance_age, main = names(insurance)[6])

```

#### Create Box and Whisker Plots for Each Numeric Attribute

```{r}
par(mar = c(1, 1, 1, 1))

boxplot(insurance[, 6], main = names(insurance)[6])
boxplot(insurance[, 2], main = names(insurance)[2])
boxplot(insurance[, 8], main = names(insurance)[8])
```

#### Create a Missingness Map to Identify Missing Data

```{r}
library(Amelia)

missmap(insurance, col = c("red", "grey"), legend = TRUE)
```

### Multivariate Plots 
#### Create a Correlation Plot 
```{r}
library(corrplot)

corrplot(cor(insurance[, c(6, 8)]), method = "circle")
```

# Data Imputation
## Handle missing values
### Are there missing values in the dataset?

```{r}
library(tidyverse)

anyNA(insurance)
```
### How many?

```{r}
library(naniar)

n_miss(insurance)
```

### What is the proportion of missing data in the entire dataset?

```{r}
prop_miss(insurance)
```

### How many missing values does each variable have?
```{r}
insurance %>% is.na() %>% colSums()
```

### What is the number and percentage of missing values grouped by each variable?

```{r}
miss_var_summary(insurance)
```

### What is the number and percentage of missing values grouped by each observation?

```{r}
miss_case_summary(insurance)
```

### Which variables contain the most missing values?

```{r}
gg_miss_var(insurance)
```

## Remove the observations with missing values

```{r}
insurance_obs <- insurance %>% filter(complete.cases(.))
dim(insurance_obs)
```


# Data transformation
## The Scale Basic Transform
### Before
```{r}
library(caret)

summary(insurance_obs)
insurance_obs_yield <- as.numeric(unlist(insurance_obs[, 8]))
hist(insurance_obs_yield, main = names(insurance_obs)[8])

model_of_the_transform <- preProcess(insurance_obs, method = c("scale"))
print(model_of_the_transform)
insurance_scale_transform <- predict(model_of_the_transform, insurance_obs)
```

### After
```{r}
summary(insurance_scale_transform)
insurance_obs_yield <- as.numeric(unlist(insurance_scale_transform[, 8]))
hist(insurance_obs_yield, main = names(insurance_scale_transform)[8])
```


## Center Data Transform

```{r}
summary(insurance_obs)
model_of_the_transform <- preProcess(insurance_obs, method = c("center"))
print(model_of_the_transform)
insurance_center_transform <- predict(model_of_the_transform, insurance_obs)
summary(insurance_center_transform)
```

## Standardize Data Transform
### Before

```{r}
summary(insurance_obs)
sapply(insurance_obs[, c(6,8)], sd)
model_of_the_transform <- preProcess(insurance_obs,
                                     method = c("scale", "center"))
print(model_of_the_transform)
insurance_standardize_transform <- predict(model_of_the_transform, insurance_obs) # nolint

```

### After

```{r}
summary(insurance_standardize_transform)
sapply(insurance_standardize_transform[, c(6,8)], sd)
```

## Normalize Data Transform

```{r}
summary(insurance_obs)
model_of_the_transform <- preProcess(insurance_obs, method = c("range"))
print(model_of_the_transform)
insurance_normalize_transform <- predict(model_of_the_transform, insurance_obs)
summary(insurance_normalize_transform)
```

## Box-Cox Power Transform 
### Before

```{r}
library(e1071)

summary(insurance_standardize_transform)

# Calculate the skewness before the Box-Cox transform
sapply(insurance_standardize_transform[, c(6,8)],  skewness, type = 2)
sapply(insurance_standardize_transform[, c(6,8)], sd)

model_of_the_transform <- preProcess(insurance_standardize_transform,
                                     method = c("BoxCox"))
print(model_of_the_transform)
insurance_box_cox_transform <- predict(model_of_the_transform,
                                       insurance_standardize_transform)
```

### After

```{r}
summary(insurance_box_cox_transform)

sapply(insurance_box_cox_transform[, c(6,8)],  skewness, type = 2)
sapply(insurance_box_cox_transform[, c(6,8)], sd)

# Calculate the skewness after the Box-Cox transform
sapply(insurance_box_cox_transform[, c(6,8)],  skewness, type = 2)
sapply(insurance_box_cox_transform[, c(6,8)], sd)
```
## Yeo-Johnson Power Transform 
### Before
```{r}
summary(insurance_standardize_transform)

# Calculate the skewness before the Yeo-Johnson transform
sapply(insurance_standardize_transform[, c(6,8)],  skewness, type = 2)
sapply(insurance_standardize_transform[, c(6,8)], sd)

model_of_the_transform <- preProcess(insurance_standardize_transform,
                                     method = c("YeoJohnson"))
print(model_of_the_transform)
insurance_yeo_johnson_transform <- predict(model_of_the_transform, # nolint
                                           insurance_standardize_transform)

```
### After
```{r}
summary(insurance_yeo_johnson_transform)

# Calculate the skewness after the Yeo-Johnson transform
sapply(insurance_yeo_johnson_transform[, c(6,8)],  skewness, type = 2)
sapply(insurance_yeo_johnson_transform[, c(6,8)], sd)

```

## PCA for Dimensionality Reduction
```{r}
summary(insurance)

model_of_the_transform <- preProcess(insurance, method =
                                       c("scale", "center", "pca"))

print(model_of_the_transform)
insurance_pca_dr <- predict(model_of_the_transform, insurance)

summary(insurance_pca_dr)
```
## PCA for Feature Extraction
```{r}
insurance_pca_fe <- princomp(cor(insurance[, c(6,8)]))
summary(insurance_pca_fe)
```

### Scree Plot 
```{r}
factoextra::fviz_eig(insurance_pca_fe, addlabels = TRUE)
```

### Loading Values
```{r}
insurance_pca_fe$rating[, 1:2]
factoextra::fviz_cos2(insurance_pca_fe, choice = "var", axes = 1:1)
```

### Biplot and Cos2 Combined Plot
```{r}
factoextra::fviz_pca_var(insurance_pca_fe, col.var = "cos2",
                         gradient.cols = c("red", "orange", "green"),
                         repel = TRUE)
```

## ICA for Dimensionality Reduction on the Boston Housing Dataset
```{r}
summary(insurance)

model_of_the_transform <- preProcess(insurance,
                                     method = c("scale", "center", "ica"),
                                     n.comp = 3)
print(model_of_the_transform)
insurance_ica_dr <- predict(model_of_the_transform, insurance)

summary(insurance_ica_dr)
```

# Resampling methods
## Split the dataset
```{r}
train_index <- createDataPartition(insurance$rating,
                                   p = 0.75,
                                   list = FALSE)
insurance_train <- insurance[train_index, ]
insurance_test <- insurance[-train_index, ]
```
## Train a Naive Bayes classifier using the training dataset
```{r}
insurance_model_nb <-
  e1071::naiveBayes(rating ~ .,
                    data = insurance_train)
```

## Test the trained model using the testing dataset 
```{r}
predictions_nb_e1071 <-
  predict(insurance_model_nb,
          insurance_test[, c("insurance.name","packagePrice", "services", "priceRage","packageType","age", "preIllness", "rating", "transactionNo")])
```

## View results
```{r}

```















































