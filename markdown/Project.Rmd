---
title: "Business Intelligence Project"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |                             |
|--------------------------------------------|----------------------------|
| **Student ID Number**                        | 119630,135844,131038,104135 |
| **Student Name**                             | beasts                      |
| **BBIT 4.2 Group**                           | A&B&C                       |
| **BI Project Group Name/ID (if applicable)** | beasts                      |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```

# Load dataset

```{r}
insurance <- read.csv("data/insurance_info.csv")

```

# Exploratory Data Analysis

### Dimensions

```{r}
# display the dimensions of your datasets
dim(insurance)
#Identify the Data Types
sapply(insurance, class)
```

## Descriptive Statistics

### Measures of frequency

```{r}
insurance_freq <- insurance$age
cbind(frequency = table(insurance_freq),
      percentage = prop.table(table(insurance_freq)) * 100)
```

### Measures of central tendency

```{r}
insurance_mode <- names(table(insurance$age))[
  which(table(insurance$age) == max(table(insurance$age)))
]
print(insurance_mode)
```

### Measures of distribution

#### Measure the variance of the age variable

```{r}
var(insurance[, 6])

```

#### Measure the standard deviation of age variable

```{r}
sd(insurance[, 6] )
```

#### Measure the kurtosis of each age variable

```{r}
library(moments)

kurtosis(insurance[, 6], na.rm = TRUE)
```

#### Measure the skewness of each variable

```{r}
skewness(insurance[, 6])
```

### Measures of relationship

#### Measure the covariance between variables

```{r}
insurance_cov <- cov(insurance[,c(8, 6)])
View(insurance_cov)
```

#### Measure the correlation between variables

```{r}
insurance_cor <- cor(insurance[, c(8, 6)])
View(insurance_cor)
```

## Inferential statistics

### Perform ANOVA

#### One-Way ANOVA

```{r}
insurance_one_way_anova <- aov(age ~ rating, data = insurance)
summary(insurance_one_way_anova)
```

#### Two-Way ANOVA

```{r}
insurance_additive_two_way_anova <- aov(age ~ rating + packagePrice, # nolint
                                           data = insurance)
summary(insurance_additive_two_way_anova)
```

## Basic Visualization

### Univariate plots

#### create histograms

```{r}
par(mar = c(4, 4, 2, 2)) 

insurance_yield <- as.numeric(unlist(insurance[, 6]))
hist(insurance_yield, main = names(insurance)[6])

```

#### Create Box and Whisker Plots for Each Numeric Attribute

```{r}
boxplot(insurance[, 6], main = names(insurance)[6])
boxplot(insurance[, 2], main = names(insurance)[2])
boxplot(insurance[, 8], main = names(insurance)[8])
```

#### Create Bar Plots for Each Categorical Attribute

```{r}
barplot(table(insurance[, 3]), main = names(insurance)[3])
```

### Multivariate Plots

#### Create a Correlation Plot

```{r}
library(corrplot)

corrplot(cor(insurance[, c(2, 6)]), method = "circle")
```

## Qualitative Data Analysis

## Contractions

### removal of special characters and conversion of lowercase

```{r}
remove_special_characters <- function(doc) {
  gsub("[^a-zA-Z0-9 ]", "", doc, ignore.case = TRUE)
}


insurance$preIllness <- sapply(insurance$preIllness, tolower) # nolint
insurance$services <- sapply(insurance$services, tolower) # nolint
insurance$packageType <- sapply(insurance$packageType, tolower) # nolint
insurance$priceRage <- sapply(insurance$priceRage, tolower) # nolint
View(insurance)
```

# Pre-prosessing and Data Transformation
## Handle missing values ----

### Are there missing values in the dataset?

```{r}
library(tidyverse)

anyNA(insurance)
```

### How many?

```{r}
library(naniar)

n_miss(insurance)
```

### What is the proportion of missing data in the entire dataset?

```{r}
prop_miss(insurance)
```

### How many missing values does each variable have?
```{r}
insurance %>% is.na() %>% colSums()
```

### What is the number and percentage of missing values grouped by each variable?

```{r}
miss_var_summary(insurance)
```

### What is the number and percentage of missing values grouped by each observation?

```{r}
miss_case_summary(insurance)
```

### Which variables contain the most missing values?

```{r}
gg_miss_var(insurance)
```

### Where are missing values located (the shaded regions in the plot)?
```{r}
library(naniar)
library(ggplot2)

vis_miss(insurance) + theme(axis.text.x = element_text(angle = 80))
```

## Remove the observations with missing values

```{r}
insurance_obs <- insurance %>% filter(complete.cases(.))
dim(insurance_obs)
```

#### Are there missing values in the dataset?

```{r}
any_na(insurance_obs)
```


# Training the Model

# Hyper-parameter Tuning and Ensembles

# Consolidation
